WEBVTT

1
00:00:00.000 --> 00:00:02.375
Hi, my name is Brian Caffo and

2
00:00:02.375 --> 00:00:06.943
this is the lecture on defining
success in data science.

3
00:00:06.943 --> 00:00:11.230
So, let's talk about success
vs failure in data science.

4
00:00:11.230 --> 00:00:15.470
So, the most positive results
in a data science experiment

5
00:00:15.470 --> 00:00:17.770
is new knowledge is created.

6
00:00:17.770 --> 00:00:22.710
But even better than that, is that
actionable decisions are made off of that

7
00:00:22.710 --> 00:00:27.670
new knowledge, so decisions are made based
on the outcome of the data analysis.

8
00:00:27.670 --> 00:00:30.150
Ideally these decisions,
the new knowledge or

9
00:00:30.150 --> 00:00:32.930
the product from the data
analysis has impact.

10
00:00:32.930 --> 00:00:36.980
And I would define another form of success

11
00:00:36.980 --> 00:00:41.800
that seems less clearly successful but
still is successful none the less,

12
00:00:41.800 --> 00:00:45.550
which is if you determine that the data
cannot inform the decision in question.

13
00:00:46.810 --> 00:00:49.640
So, or
the knowledge that you'd like to gain.

14
00:00:49.640 --> 00:00:53.090
And if that's conclusive then
you know where else to look.

15
00:00:53.090 --> 00:00:54.530
So that is a form of success.

16
00:00:54.530 --> 00:00:57.880
Maybe it's a negative form of success but
it, but is a form of success.

17
00:00:57.880 --> 00:01:00.250
Let's talk about the opposite.

18
00:01:00.250 --> 00:01:05.720
What are ways in which data signs
experiments can really be unsuccessful?

19
00:01:05.720 --> 00:01:09.460
Well, the decisions
are made in the opposite

20
00:01:09.460 --> 00:01:11.480
of the direction of clear evidence.

21
00:01:11.480 --> 00:01:16.350
That's probably the worst output of
a data science experiment, where all

22
00:01:16.350 --> 00:01:20.240
the evidence is clear, and the decisions
are made in the opposite direction.

23
00:01:20.240 --> 00:01:23.570
Another problem is that maybe
the results are equivocal.

24
00:01:23.570 --> 00:01:25.730
So the studies may be underpowered.

25
00:01:25.730 --> 00:01:29.690
Or maybe you didn't measure what
you had hoped to when you, or

26
00:01:29.690 --> 00:01:31.560
what you'd liked to have measured.

27
00:01:31.560 --> 00:01:35.800
So even though you get conclusive results
the measurement is off by a little bit.

28
00:01:36.910 --> 00:01:39.830
So these things can all happen and

29
00:01:39.830 --> 00:01:45.610
lead to a result that neither supports nor
refutes so a set of hypotheses.

30
00:01:47.810 --> 00:01:51.300
Also in this case is the decision
would not be obvious.

31
00:01:52.700 --> 00:01:55.470
Another instance is just
where the uncertainty just

32
00:01:55.470 --> 00:01:57.540
prevents new knowledge from being created.

33
00:01:57.540 --> 00:02:01.730
I would emphasize that a lot of the things
that we're going to talk about: data

34
00:02:01.730 --> 00:02:06.480
science in the ideal versus data science
In real life is covered in week four,

35
00:02:06.480 --> 00:02:10.950
the fourth class of this specialization
called Data Science in Real Life.

36
00:02:10.950 --> 00:02:11.740
So in this lecture,

37
00:02:11.740 --> 00:02:17.320
I'd just like to go over some examples
of when data science was a real success,

38
00:02:17.320 --> 00:02:21.580
and maybe some examples where data
science wasn't so successful.

39
00:02:21.580 --> 00:02:24.240
Well actually I don't think I cover
anywhere it wasn't so successful,

40
00:02:24.240 --> 00:02:29.150
but I cover an instance where
some negative things happened.

41
00:02:30.550 --> 00:02:36.540
I think if anyone were to ask anyone
about defining success in data science,

42
00:02:36.540 --> 00:02:39.880
the first thing that comes to
everyone's mind is Moneyball.

43
00:02:39.880 --> 00:02:41.460
And if you haven't heard of Moneyball, and

44
00:02:41.460 --> 00:02:44.630
I promise as the have some
other examples as well.

45
00:02:46.450 --> 00:02:51.060
But if you haven't heard of Moneyball,
Moneyball was this brilliant novel written

46
00:02:51.060 --> 00:02:56.100
my Michael Lewis on the Oakland A's
baseball team and their manager and

47
00:02:56.100 --> 00:03:01.770
how they started using data science to
help them improve their performance.

48
00:03:01.770 --> 00:03:06.260
And here's this great plot from
538 where it shows the standard

49
00:03:06.260 --> 00:03:10.220
deviations from the average payroll of
the teams versus the win percentage.

50
00:03:10.220 --> 00:03:13.600
So if you look at Oakland,
the clear outlier of this relationship,

51
00:03:14.610 --> 00:03:18.170
it's one standard deviation
below the average payroll.

52
00:03:18.170 --> 00:03:22.490
It is well above what will be expected for
the win percentage for that team.

53
00:03:22.490 --> 00:03:23.560
Now, it's not the best.

54
00:03:23.560 --> 00:03:27.140
Way up in the right is the New York
Yankees or the Red Sox or something,

55
00:03:27.140 --> 00:03:31.060
I think it was the Yankees on the upper
right, that had the highest payroll and

56
00:03:31.060 --> 00:03:32.940
the highest win percentage.

57
00:03:32.940 --> 00:03:36.860
But Oakland was well above what
would be predicted from them

58
00:03:36.860 --> 00:03:41.290
based on using data science
in their organization.

59
00:03:41.290 --> 00:03:45.220
Okay so that's a very famous example, now
if you haven't read that book it's a great

60
00:03:45.220 --> 00:03:47.510
motivating book for
the field of data science.

61
00:03:49.100 --> 00:03:53.270
But I want to cover one of my favorite
examples of a data scientist maybe one of

62
00:03:53.270 --> 00:03:57.970
the earliest examples of a data scientist,
and that was Florence Nightingale.

63
00:03:57.970 --> 00:04:02.570
So you've probably all heard of
Florence Nightingale in her fabulous work

64
00:04:02.570 --> 00:04:07.780
as a nurse, but you may have less likely

65
00:04:07.780 --> 00:04:11.380
have heard of her contributions to
the field of statistics and graphics.

66
00:04:11.380 --> 00:04:14.730
And this is one of her beautiful
graphs that she created here.

67
00:04:14.730 --> 00:04:21.720
She's one of the really early
developers of modern graphs.

68
00:04:21.720 --> 00:04:23.490
And there's a lot written about it.

69
00:04:23.490 --> 00:04:26.660
In some of the books,
like Tufte's books on graphing.

70
00:04:26.660 --> 00:04:30.130
And it's great reading if you want
something interesting to read up on.

71
00:04:31.340 --> 00:04:35.980
But in this particular graph and in
this work, she showed that the soldiers,

72
00:04:35.980 --> 00:04:38.130
the British soldiers in the Crimean war,

73
00:04:38.130 --> 00:04:43.230
were more likely to die from Cholera than
they were to die on the battlefield.

74
00:04:43.230 --> 00:04:49.150
And this was a report that she gave to
the royalty that actually changed policy.

75
00:04:49.150 --> 00:04:52.470
So this is a great example of using data,

76
00:04:52.470 --> 00:04:56.650
creating visualizations in an early
example of data science to impact policy.

77
00:04:56.650 --> 00:05:02.120
And I would say this idea of
using data science to inform

78
00:05:02.120 --> 00:05:07.960
infectious disease prevention is is
very old and has had it's ups and downs.

79
00:05:07.960 --> 00:05:10.840
And so this,
let's talk about one of the downs.

80
00:05:10.840 --> 00:05:15.591
Another one of my heroes is this
person right here, Semmelweis.

81
00:05:15.591 --> 00:05:21.617
Semmelweis was a physician, but
he was also a very astute scientist and

82
00:05:21.617 --> 00:05:25.936
he was concerned about
the rates of infections when

83
00:05:25.936 --> 00:05:30.756
contrasting two clinics in his area for,
two clinics for

84
00:05:30.756 --> 00:05:36.281
pregnant women and he wanted to
figure out why the outcomes were so

85
00:05:36.281 --> 00:05:40.827
much worse for one of the clinics and
he used the data.

86
00:05:40.827 --> 00:05:45.532
And he used a lot of scientific and
critical thinking to figure out well

87
00:05:45.532 --> 00:05:50.237
before the advent of the germ theory
of disease that it was the fact that

88
00:05:50.237 --> 00:05:53.987
the medical students were
operating on the cadavers and

89
00:05:53.987 --> 00:05:59.440
then treating the women and were actually
carrying over some sort of infection.

90
00:05:59.440 --> 00:06:04.010
He called it something with the word
cadaver in it, some sort of cadaverous

91
00:06:04.010 --> 00:06:10.530
infection, because this was before
the germ theory of disease.

92
00:06:10.530 --> 00:06:14.310
So at any rate what's negative about
this I mentioned that this was negative.

93
00:06:14.310 --> 00:06:19.229
What's negative about this was
that in his solution was hand

94
00:06:19.229 --> 00:06:24.530
washing and
what was negative about this was policies

95
00:06:24.530 --> 00:06:29.910
about hand washing weren't executed well
after this research, well after his death.

96
00:06:29.910 --> 00:06:34.590
Even now, there's still a lot of work

97
00:06:34.590 --> 00:06:39.420
being done trying to enforce hand washing
in hospitals to prevent infections.

98
00:06:39.420 --> 00:06:44.193
So his work has this long legacy, and this
long legacy that's still being research.

99
00:06:44.193 --> 00:06:49.066
And unfortunately it was a long time and
a lot of lives lost by virtue

100
00:06:49.066 --> 00:06:53.853
of ignoring what was clear data and
especially, even if this data

101
00:06:53.853 --> 00:06:59.005
wasn't the clearest data,
the data piled up on top of it afterwards.

102
00:06:59.005 --> 00:07:04.061
And so this maybe wasn't the best example
of the, of the successful outcome

103
00:07:04.061 --> 00:07:09.591
of data science experiment despite the
experiment actually being conducted well I

104
00:07:09.591 --> 00:07:14.950
wanted to also talk about another instance
from an alumni from our department.

105
00:07:14.950 --> 00:07:19.650
This physician here named Dorry Segev who
actually also got a masters degree in bio

106
00:07:19.650 --> 00:07:25.640
statistics along the way and
he has several great examples

107
00:07:25.640 --> 00:07:31.840
of using data science to inform
decisions and policy making.

108
00:07:31.840 --> 00:07:34.280
So in one example, and
I would say what he's ultimately,

109
00:07:34.280 --> 00:07:37.950
what his career seems to be shaping up as,
from my outside viewpoint,

110
00:07:37.950 --> 00:07:42.530
is he's applying the field of data
science to transplantation research,

111
00:07:42.530 --> 00:07:47.262
whereas traditional transplantation
research was really all about,

112
00:07:47.262 --> 00:07:51.220
you know, improving technique for example.

113
00:07:51.220 --> 00:07:55.930
He's really working on data bases and
performing a lot of statistics on large

114
00:07:55.930 --> 00:08:02.030
populations of transplant recipients and
donors, etc., and really impacting policy.

115
00:08:03.230 --> 00:08:07.770
So, in essence, he's really moneyballing
transplantation in a lot of ways.

116
00:08:07.770 --> 00:08:13.150
And one really great success
he had was to help get

117
00:08:13.150 --> 00:08:18.600
policies enacted to allow for
HIV positive patients to be

118
00:08:18.600 --> 00:08:22.690
donors just for research purposes,
to understand whether or

119
00:08:22.690 --> 00:08:28.850
not they can be donors to other
HIV potential kidney recipients.

120
00:08:28.850 --> 00:08:32.950
And so this was,
he did some data science work

121
00:08:32.950 --> 00:08:37.690
on estimating the potential pool of HIV
infected deceased organ donors, and

122
00:08:37.690 --> 00:08:42.810
this lead to new legislation, and
here's President Obama signing it.

123
00:08:42.810 --> 00:08:46.970
This is going to allow researchers
to study this phenomenon,

124
00:08:46.970 --> 00:08:51.220
and may in the long run,
save quite a few lives.

125
00:08:51.220 --> 00:08:54.840
I'd say, also here's this,
I put a link here.

126
00:08:54.840 --> 00:09:00.500
Here's this cute documentary created
by Andrew Rizzaro on Dorian and

127
00:09:00.500 --> 00:09:02.910
his wife who's a computer
scientist at the Naval Academy.

128
00:09:04.330 --> 00:09:05.600
And on the problem about,

129
00:09:05.600 --> 00:09:10.900
I'm about to talk about, there's another
really great data science success.

130
00:09:10.900 --> 00:09:13.960
So watch this YouTube documentary,
it's really great.

131
00:09:13.960 --> 00:09:19.930
So, anyway, another thing that they
studied was considering this problem,

132
00:09:19.930 --> 00:09:23.710
so here I have to shades of red,
the first row is a couple.

133
00:09:23.710 --> 00:09:27.760
The left member of the couple,
let's say they're spouses, the left

134
00:09:27.760 --> 00:09:32.340
member of the couple wants to donate a
kidney to the right member of the couple.

135
00:09:32.340 --> 00:09:34.100
And the same thing is true for
the second row.

136
00:09:35.200 --> 00:09:38.850
However, they're not matches,
so they can't be donors.

137
00:09:38.850 --> 00:09:43.470
However, imagine the case that the pair
of them could be donors to the others.

138
00:09:43.470 --> 00:09:48.960
And you could imagine mining a data set
to do this, then you could put everyone

139
00:09:48.960 --> 00:09:54.470
under the knife at the same time and
do the donation, do the donation this way.

140
00:09:54.470 --> 00:10:00.430
So the second spouse gives it to the first
spouse's recipient and vice-versa.

141
00:10:00.430 --> 00:10:05.260
There's nothing that would stop you from
stopping at pairs of kidney donation.

142
00:10:05.260 --> 00:10:09.980
You could for example do three,
where none of the pairs would match up but

143
00:10:09.980 --> 00:10:13.200
if you had three that matched up
in the right way, you could do it.

144
00:10:13.200 --> 00:10:19.760
Well, Dory, well Summer,
his wife who's the computer scientist at

145
00:10:19.760 --> 00:10:24.560
the Naval Academy, wrote the algorithms
that mine the donation data set to find,

146
00:10:24.560 --> 00:10:28.890
and the potential donors,
to find large collections of matches

147
00:10:30.080 --> 00:10:34.510
of pairs of kidney matches
in ways that would work out.

148
00:10:34.510 --> 00:10:41.010
And Dorie and other members of
the transplant teams here at Johns Hopkins

149
00:10:41.010 --> 00:10:45.500
have done extremely large multi-way
simultaneous kidney transplantations.

150
00:10:45.500 --> 00:10:47.510
Many of these were reported
on in the New York Times.

151
00:10:47.510 --> 00:10:51.390
So I think this idea of
moneyballing transplantation.

152
00:10:51.390 --> 00:10:55.250
Is really transforming the field and
it's really,

153
00:10:55.250 --> 00:10:59.470
I have to say it's great to
see one of our alumni even if

154
00:10:59.470 --> 00:11:04.260
we were only a minor part of his
education doing such great work

155
00:11:04.260 --> 00:11:08.400
especially applying bio statistics and
data science in such a profound way.

156
00:11:11.070 --> 00:11:15.370
I want to talk anyway,
this is another example for biostatistics.

157
00:11:15.370 --> 00:11:18.520
An example where the measurement
can't do what you'd hope for.

158
00:11:18.520 --> 00:11:21.460
And this is my friend and
colleague Martin Linquist.

159
00:11:22.590 --> 00:11:26.530
We work in the field of FMRI, and
something that a lot of people want to do

160
00:11:26.530 --> 00:11:28.680
is say that when this area
of the brain activates,

161
00:11:28.680 --> 00:11:31.410
then afterwards this area of
the brain activates, inactivates.

162
00:11:31.410 --> 00:11:36.090
And what Martin basically proved using a
collection of data, science, physics, and

163
00:11:36.090 --> 00:11:39.590
biology, was he showed
that that's not actually

164
00:11:39.590 --> 00:11:43.030
possible with the measurements
that are being collected.

165
00:11:44.220 --> 00:11:47.600
So that's a negative result in a sense
because what everyone wants to do has been

166
00:11:47.600 --> 00:11:48.870
proven can't be done.

167
00:11:48.870 --> 00:11:53.610
However, in a positive sense,
this has shed light on not

168
00:11:53.610 --> 00:11:57.860
wasted a lot of people's time now trying
to do this and it was an important result.

169
00:11:57.860 --> 00:12:01.840
And also people who wanted to do this
have you know continued to try to refine

170
00:12:01.840 --> 00:12:05.530
the technique the way in which
the data was collected to improve it.

171
00:12:05.530 --> 00:12:09.530
So I just want to reiterate this point
that another way in which success can

172
00:12:09.530 --> 00:12:11.279
occur in data science

173
00:12:12.340 --> 00:12:16.910
is if you can demonstrate that you can't
answer the kinds of questions that you

174
00:12:16.910 --> 00:12:21.050
want to with the data that
you have available to you.

175
00:12:21.050 --> 00:12:26.990
And I want to end on a more positive
note that on this idea of impact,

176
00:12:26.990 --> 00:12:32.710
and one of the best ways that a data
science experiment can have impact

177
00:12:32.710 --> 00:12:37.220
as if the product of the data science
experiment is some app that everyone uses.

178
00:12:37.220 --> 00:12:38.920
And I just want to make a plug for

179
00:12:38.920 --> 00:12:43.300
my own class in the other course area
data science specialization that we

180
00:12:43.300 --> 00:12:46.710
teach called Data Products,
developing data products.

181
00:12:46.710 --> 00:12:52.250
In the data products
class you create an app,

182
00:12:52.250 --> 00:12:57.460
a data science app, and sometimes
people tweak them out on Twitter.

183
00:12:57.460 --> 00:13:00.410
If you go to #mydataproduct
you can see some of them.

184
00:13:00.410 --> 00:13:03.190
Here, I took this one from
this one that I liked.

185
00:13:03.190 --> 00:13:04.900
I picked one relatively at random but

186
00:13:04.900 --> 00:13:06.919
I liked it because it had
lots of dowels and inputs.

187
00:13:08.330 --> 00:13:13.620
Where, you know,
this student, Brent, put in,

188
00:13:13.620 --> 00:13:17.910
you know you can put in
a lot of various factors and

189
00:13:17.910 --> 00:13:23.550
get your retirement
savings goal out of it.

190
00:13:23.550 --> 00:13:28.560
So, and any rate,
of course some of the most well-know

191
00:13:28.560 --> 00:13:33.190
examples of data science apps are all
the recommender systems that occur

192
00:13:33.190 --> 00:13:37.950
when we purchase goods from online
retailers and things like that.

193
00:13:37.950 --> 00:13:42.170
So one of the best ways to have
an impact is to create an app.

194
00:13:42.170 --> 00:13:44.330
And we're seeing that so
often now in our lives.

195
00:13:44.330 --> 00:13:46.810
it's hard to even enumerate them all.

196
00:13:46.810 --> 00:13:51.550
I think it's hard to even go through
a day without using a data science app.

197
00:13:51.550 --> 00:13:54.610
Okay, so
in today's lecture we talked a lot about

198
00:13:54.610 --> 00:13:57.220
different ways in which data
science can be successful and

199
00:13:57.220 --> 00:14:00.660
maybe even a few where it can
be a little less successful.

200
00:14:00.660 --> 00:14:02.900
If you want a lot more
discussion about the,

201
00:14:02.900 --> 00:14:07.920
what to do when you're data science
experiment is a little bit foggier.

202
00:14:07.920 --> 00:14:12.600
The week 4 class data science
in real life, will cover that.

203
00:14:12.600 --> 00:14:16.990
However, in this case I hope this gets you
thinking about, for your own data science

204
00:14:16.990 --> 00:14:21.850
experiments, and the ones that you're
managing, what would define success.

205
00:14:21.850 --> 00:14:24.250
Thanks, and I look forward to seeing
you in some of the next lectures.