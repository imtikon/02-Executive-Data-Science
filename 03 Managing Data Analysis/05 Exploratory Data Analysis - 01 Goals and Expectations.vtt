WEBVTT

1
00:00:00.510 --> 00:00:03.952
Exploratory data analysis is an important
part of any data analysis process.

2
00:00:03.952 --> 00:00:07.679
This lecture discusses the goals
of EDA and what to expect from it.

3
00:00:12.104 --> 00:00:16.278
Some of the key questions that you
wanna think about before engaging in

4
00:00:16.278 --> 00:00:19.673
an exploratory data analysis process,
are basically,

5
00:00:19.673 --> 00:00:24.290
do you have the right data to answer
the question that you’re interested in?

6
00:00:24.290 --> 00:00:26.450
And then, do you need to get other data,

7
00:00:26.450 --> 00:00:29.160
if you don’t have the right data,
to answer your question?

8
00:00:29.160 --> 00:00:33.270
And then finally, given what you see from
the data, and given kinda what you make

9
00:00:33.270 --> 00:00:36.370
of everything that’s going on in there,
do you have the right question?

10
00:00:36.370 --> 00:00:39.370
Cuz it could be that, maybe,
you thought you had the right question.

11
00:00:39.370 --> 00:00:41.112
And you thought you had
the right data set, but

12
00:00:41.112 --> 00:00:43.658
when looking around in the data set and
exploring what's in there,

13
00:00:43.658 --> 00:00:46.262
you realize that maybe the question
is better asked a different way.

14
00:00:46.262 --> 00:00:50.414
Or maybe you need to just slightly refine
the question, make it more specific, or

15
00:00:50.414 --> 00:00:52.880
maybe focus on specific variables.

16
00:00:52.880 --> 00:00:56.390
So the goal of EDA is to get
a chance to look at the data,

17
00:00:56.390 --> 00:00:59.080
see if you've got the right data,
do you need to get more?

18
00:00:59.080 --> 00:01:01.310
And do you need to refine
your question at all?

19
00:01:01.310 --> 00:01:02.180
In this lecture,

20
00:01:02.180 --> 00:01:07.310
we're gonna talk about whether you have
the right data to answer your question.

21
00:01:07.310 --> 00:01:09.840
And then,
another goal of exploratory data analysis,

22
00:01:09.840 --> 00:01:14.870
assuming you pass that first part,
is to think about how can you develop

23
00:01:14.870 --> 00:01:17.920
a sketch of kinda what the answer
to your question might be.

24
00:01:17.920 --> 00:01:21.150
So the idea, so one of the end products
of exploratory data analysis is to really

25
00:01:21.150 --> 00:01:23.670
get a sense of whether
the solution is out,

26
00:01:23.670 --> 00:01:26.660
whether the solution exists,
and what it might look at.

27
00:01:26.660 --> 00:01:29.950
And then from there, if you wanna
continue, you might go onto something more

28
00:01:29.950 --> 00:01:32.070
like formal modeling which
we'll talk about later.

29
00:01:32.070 --> 00:01:36.130
So this lecture we'll talk about figuring
our whether you've got the right data for

30
00:01:36.130 --> 00:01:37.120
the job.

31
00:01:37.120 --> 00:01:40.377
Now, I assume you've already
formulated your question, but

32
00:01:40.377 --> 00:01:44.630
it's good here to always double check to
make sure that it's as sharp as it can be.

33
00:01:44.630 --> 00:01:48.741
So that you can kind of reduce the number
of variables or the kind of fact

34
00:01:48.741 --> 00:01:53.215
features that you might want to look at,
before you kind of go ahead, okay?

35
00:01:53.215 --> 00:01:57.630
Now the first thing you want to do, of
course, is you have to read in the data.

36
00:01:57.630 --> 00:02:01.590
You can't do an exploratory data
analysis without reading in the data.

37
00:02:01.590 --> 00:02:03.350
But, assuming you can do that,

38
00:02:03.350 --> 00:02:06.790
the thing that I like to do is
what I call check the packaging.

39
00:02:06.790 --> 00:02:10.840
Imagine you've got some box, and
there's something inside you wanna get at.

40
00:02:10.840 --> 00:02:14.430
And you can't get at it yet, and so you
kinda shake it around, maybe measure it.

41
00:02:14.430 --> 00:02:15.720
You know, see how big it is.

42
00:02:15.720 --> 00:02:17.370
Is it bigger than a bread box?

43
00:02:17.370 --> 00:02:20.200
And see what kind noises does
it make when you shake it.

44
00:02:20.200 --> 00:02:20.810
Things like that.

45
00:02:20.810 --> 00:02:22.620
So that's kind of what you're trying
to do with your data set here.

46
00:02:22.620 --> 00:02:26.090
Your data set is the thing that's inside
the box but you want to make sure,

47
00:02:26.090 --> 00:02:28.480
kind of see what's, everything's
kind of the right shape and size.

48
00:02:28.480 --> 00:02:30.515
So some of the things
that I like to check are,

49
00:02:30.515 --> 00:02:32.720
do you have the right number of rows and
columns?

50
00:02:32.720 --> 00:02:37.085
If the way that you got this data said
that you were expecting there to be 1,000

51
00:02:37.085 --> 00:02:40.832
rows, then there should be 1,000
rows in the table for example.

52
00:02:40.832 --> 00:02:45.417
If there are gonna be 60 features,
there should be 60 columns, for example,

53
00:02:45.417 --> 00:02:46.090
in a table.

54
00:02:46.090 --> 00:02:49.300
So just make sure you got
those dimensions right.

55
00:02:49.300 --> 00:02:51.500
Basic details about
the packaging of a data set.

56
00:02:53.010 --> 00:02:56.190
If you were told that certain variables
were gonna be included in the data set,

57
00:02:56.190 --> 00:02:59.390
just check to see that they are in
fact included in the data set, right?

58
00:02:59.390 --> 00:03:00.490
It's a very simple check.

59
00:03:00.490 --> 00:03:03.310
You don't have to look at
any data to figure that out.

60
00:03:03.310 --> 00:03:05.020
You just basically have
to look at the metadata,

61
00:03:05.020 --> 00:03:08.140
things like the variable names and
the number of rows, for example.

62
00:03:08.140 --> 00:03:12.100
And then if there's any other
metadata that you might need,

63
00:03:12.100 --> 00:03:14.780
things like codebooks, things that
describe what the variables are,

64
00:03:14.780 --> 00:03:16.770
make sure that comes with the data too,
okay.

65
00:03:16.770 --> 00:03:20.710
So this could all be done without
actually looking at any numbers yet.

66
00:03:22.030 --> 00:03:25.345
Now, the next thing I like to do is
to check the edges of the data set.

67
00:03:25.345 --> 00:03:29.441
And so for example, if you're looking
at a table, I like to check the top and

68
00:03:29.441 --> 00:03:30.148
the bottom.

69
00:03:30.148 --> 00:03:34.350
Okay, so just look at the first few rows
and then maybe look at the last few rows.

70
00:03:34.350 --> 00:03:39.230
So the first few rows are helpful just to
make sure you've got the right numbers

71
00:03:39.230 --> 00:03:41.370
there, the kind of things
you were expecting to see.

72
00:03:41.370 --> 00:03:44.570
I find it's very useful to look at
the last few rows just to make sure, for

73
00:03:44.570 --> 00:03:46.722
example, that the data
set is read in properly,

74
00:03:46.722 --> 00:03:50.120
that you've got all of the data
that you were expecting to get.

75
00:03:50.120 --> 00:03:54.030
Often in data files, there's some
junk at the end, some comments maybe,

76
00:03:54.030 --> 00:03:55.750
just some notes that someone put in there,

77
00:03:55.750 --> 00:03:58.220
especially if they were exported
from an Excel spreadsheet.

78
00:03:59.280 --> 00:04:01.470
So you usually don't want to
read that kind of stuff in, so

79
00:04:01.470 --> 00:04:04.280
looking at the bottom of the data set can,
so to speak,

80
00:04:04.280 --> 00:04:07.360
can kind of help you to see if
there's any of that junk down there.

81
00:04:07.360 --> 00:04:10.290
And you want to check to see is
the data formatted correctly?

82
00:04:10.290 --> 00:04:13.320
Does it look like the right numbers
are in the right columns and

83
00:04:13.320 --> 00:04:15.310
the right numbers are in the right rows?

84
00:04:15.310 --> 00:04:17.830
Sometimes those things can
be shifted by one or two.

85
00:04:17.830 --> 00:04:20.880
So you wanna make sure you've got
everything kinda correct there.

86
00:04:20.880 --> 00:04:24.734
If you've got data, for example with
dates, often looking at the top and

87
00:04:24.734 --> 00:04:27.904
the bottom can be useful because
if they're sorted by date,

88
00:04:27.904 --> 00:04:29.790
you can see if the range is correct.

89
00:04:29.790 --> 00:04:32.680
You know, if the earliest and
latest dates are correct.

90
00:04:32.680 --> 00:04:35.930
And so that's another thing
that you might wanna check for.

91
00:04:35.930 --> 00:04:41.150
And so, just looking at the very edges of
the data set can be very useful to flag

92
00:04:41.150 --> 00:04:47.990
a number of basic problems that can very
often occur and are usually easy to fix.

93
00:04:47.990 --> 00:04:50.620
But once you kind of get
into a data analysis,

94
00:04:50.620 --> 00:04:54.620
if you discover these things later, it can
be a real pain in the neck to deal with.

95
00:04:54.620 --> 00:04:57.870
So the next item that I always try to
think about when I'm looking at a new data

96
00:04:57.870 --> 00:05:01.330
set, I'm just getting involved in
a data analysis is what I call ABC,

97
00:05:01.330 --> 00:05:03.710
always be checking your Ns, okay?

98
00:05:03.710 --> 00:05:07.830
So every aspect of your data set is
gonna have some kind of count or

99
00:05:07.830 --> 00:05:08.760
number associated with it.

100
00:05:08.760 --> 00:05:11.750
For example, there's gonna be
a total number of observations, or

101
00:05:11.750 --> 00:05:13.220
your sample size.

102
00:05:13.220 --> 00:05:14.580
Is that what you expect it to be?

103
00:05:14.580 --> 00:05:17.021
Are you expecting a certain
number of columns?

104
00:05:17.021 --> 00:05:21.247
There's going to be a number of columns,
you should always check that end.

105
00:05:21.247 --> 00:05:25.105
But then also within the data set,

106
00:05:25.105 --> 00:05:31.370
there's going to be a certain
numbers that you expect.

107
00:05:31.370 --> 00:05:34.060
For example,
if you have a number of subjects,

108
00:05:34.060 --> 00:05:37.840
you wanna count the number of subjects or
units in your analysis.

109
00:05:37.840 --> 00:05:42.040
If every subject was measured three times,
you wanna make sure that every subjects

110
00:05:42.040 --> 00:05:44.400
got actually three measurements
associated with it, right?

111
00:05:44.400 --> 00:05:48.620
So there's all kinds of just ends that
you can check within your data set and

112
00:05:48.620 --> 00:05:51.160
kind of around your data set to
make sure that everything is kind

113
00:05:51.160 --> 00:05:53.280
of in structured in place, okay?

114
00:05:53.280 --> 00:05:56.480
So, the next thing you wanna do is
actually just look at your data.

115
00:05:56.480 --> 00:05:59.470
And to me,
the easiest way to look at the data to

116
00:05:59.470 --> 00:06:02.820
determine if there are any
problems is to make a plot.

117
00:06:02.820 --> 00:06:06.010
So making a plot is useful in two ways.

118
00:06:06.010 --> 00:06:10.360
The first way it's useful is for setting
expectations about your data, okay?

119
00:06:10.360 --> 00:06:13.335
So when you look at a plot,
you get a sense of kinda how the variables

120
00:06:13.335 --> 00:06:15.688
are related to each other
if you make a scatter plot.

121
00:06:15.688 --> 00:06:16.920
Now if you make a box plot,

122
00:06:16.920 --> 00:06:20.862
you can look at the distributions of the
variables to see whether they're skewed.

123
00:06:20.862 --> 00:06:23.429
Are there positive and negative values,

124
00:06:23.429 --> 00:06:27.690
are you expecting positive and
negative values, things like that?

125
00:06:27.690 --> 00:06:33.060
So plots can very quickly reveal this
kind of information in a way that often,

126
00:06:33.060 --> 00:06:34.470
tables cannot.

127
00:06:34.470 --> 00:06:37.280
Because one of the things
that plots give you

128
00:06:37.280 --> 00:06:40.660
is they give you a summary
plus a deviation.

129
00:06:40.660 --> 00:06:43.510
And very often,
tables will only give you the summary.

130
00:06:43.510 --> 00:06:45.850
So for example,
they give you the mean or the median.

131
00:06:45.850 --> 00:06:49.520
But a plot will allow you to
visualize both the mean and

132
00:06:49.520 --> 00:06:51.230
the deviations from the mean.

133
00:06:51.230 --> 00:06:56.148
And so you'll be able to see if there
are very large deviations that are perhaps

134
00:06:56.148 --> 00:06:57.052
unexpected.

135
00:06:57.052 --> 00:07:01.135
Or there are kind of values that, for
example, negative values or maybe they're

136
00:07:01.135 --> 00:07:05.022
positive values that you weren't
expecting that don't appear correct.

137
00:07:05.022 --> 00:07:08.160
All right, so
I think a plot is very important to make.

138
00:07:08.160 --> 00:07:11.530
Not that there is no role for
tables in data analysis, but a plot has

139
00:07:11.530 --> 00:07:16.230
a unique ability, in my opinion,
to show you both what to expect and

140
00:07:16.230 --> 00:07:20.710
what not to expect in the sense of what
the deviations are from that expectation.

141
00:07:20.710 --> 00:07:22.770
So look at the data and make a plot.

142
00:07:24.390 --> 00:07:27.430
The next useful thing that I like
to do with data sets is to try to

143
00:07:27.430 --> 00:07:31.010
validate it with at least
one external data source.

144
00:07:31.010 --> 00:07:35.078
So obviously how you do this will
depend on exactly what your problem is,

145
00:07:35.078 --> 00:07:38.223
what your question is and
the data that you have at hand.

146
00:07:38.223 --> 00:07:43.039
But it's nice to be able to check
certain aspects of your data set,

147
00:07:43.039 --> 00:07:45.707
that they match something outside.

148
00:07:45.707 --> 00:07:49.594
So that you know that the data you got
are at least kinda within the realm of

149
00:07:49.594 --> 00:07:51.080
reality.

150
00:07:51.080 --> 00:07:55.310
And even just a single
number can be useful.

151
00:07:55.310 --> 00:07:58.870
So, for example, if you know that
the average level of some feature

152
00:07:58.870 --> 00:08:02.510
In your population is, on the order
of plus or minus whatever, ten.

153
00:08:03.570 --> 00:08:06.594
And if you look in your data set, and you
have a measurement on that same feature,

154
00:08:06.594 --> 00:08:08.254
and it looks like
the average is around ten.

155
00:08:08.254 --> 00:08:11.685
Well that can be useful just so
you know that roughly the mean of your,

156
00:08:11.685 --> 00:08:13.460
the distribution in your data set,

157
00:08:13.460 --> 00:08:17.600
is corresponds to kind of what you
might expect in the population.

158
00:08:17.600 --> 00:08:20.960
Another thing you can do is
to look at some measurements

159
00:08:20.960 --> 00:08:22.710
that you have in your data set.

160
00:08:22.710 --> 00:08:26.250
And compare it with measurements that are
similar, if not exactly the same feature,

161
00:08:26.250 --> 00:08:28.680
but things that you would
expect to be correlated with

162
00:08:28.680 --> 00:08:29.900
what’s there in your data set.

163
00:08:29.900 --> 00:08:31.728
And check to see if they’re
actually correlated, right?

164
00:08:31.728 --> 00:08:36.735
So that way, you can get a sense of,
okay well, whatever I’m measuring in my

165
00:08:36.735 --> 00:08:41.895
data set, it’s measuring the same thing
that this other metric is looking at,

166
00:08:41.895 --> 00:08:44.917
and so
there may be some kinda validity there.

167
00:08:44.917 --> 00:08:49.187
So just doing a little check to see that
your data matches with something that's

168
00:08:49.187 --> 00:08:51.748
kind of independent and
outside your data set.

169
00:08:51.748 --> 00:08:56.588
Can give you a little bit more confidence
in the idea that your data set

170
00:08:56.588 --> 00:09:01.460
is properly formatted and
it came to you in the right way.

171
00:09:01.460 --> 00:09:04.354
So now that you've checked the packaging,
you've checked your ends,

172
00:09:04.354 --> 00:09:06.400
you looked at the top and
the bottom of the data set.

173
00:09:06.400 --> 00:09:10.165
You've made maybe a simple plot just
to kind of visualize the data, and

174
00:09:10.165 --> 00:09:13.170
you've validated with one
external data source.

175
00:09:13.170 --> 00:09:15.147
The next thing to do is to try
to take a stab at your solution.

176
00:09:15.147 --> 00:09:18.073
And I won't get into
that very much right now,

177
00:09:18.073 --> 00:09:22.890
but my only point to make here is that
you should try the easy solution first.

178
00:09:22.890 --> 00:09:26.490
Okay, what is the most obvious
thing that you would do

179
00:09:26.490 --> 00:09:29.180
in the kind of simplest of scenarios,
right?

180
00:09:29.180 --> 00:09:32.560
So, cuz you wanna be able to
start with something simple and

181
00:09:32.560 --> 00:09:35.510
then you can kind of get more
complex a little bit later.

182
00:09:35.510 --> 00:09:38.010
But often the simplest thing
can be very revealing.

183
00:09:38.010 --> 00:09:39.690
That's the key, and

184
00:09:39.690 --> 00:09:43.640
often the more sophisticated approaches
will give you a little bit more insight.

185
00:09:43.640 --> 00:09:47.680
But not any more than you would have
gotten from just looking at a very simple

186
00:09:47.680 --> 00:09:51.640
picture or a table or whatever it is
that you've tried to do it first.

187
00:09:51.640 --> 00:09:56.510
And the goal of this is really to start
developing what I call a primary model.

188
00:09:56.510 --> 00:09:59.250
So a primary model is
the model of which you kind of

189
00:09:59.250 --> 00:10:01.710
base your other analysis around, right?

190
00:10:01.710 --> 00:10:03.640
And it's not gonna be permanent.

191
00:10:03.640 --> 00:10:06.200
You may change what
the primary model is later.

192
00:10:06.200 --> 00:10:09.940
But it's the kinda focal point,
your initial focal point for

193
00:10:09.940 --> 00:10:13.150
your analysis, and then you'll
try all kinds of other analyses.

194
00:10:13.150 --> 00:10:15.350
Secondary analyses that I call them,

195
00:10:15.350 --> 00:10:18.550
that will try to test whether your
primary analysis is appropriate or not.

196
00:10:18.550 --> 00:10:21.810
And many times you'll find that actually
your primary analysis was not right and

197
00:10:21.810 --> 00:10:24.750
you'll focus on a different model and
you make that your primary model.

198
00:10:24.750 --> 00:10:27.960
But sometimes your primary
model will hold up and

199
00:10:27.960 --> 00:10:29.090
then you'll be able to stick with it.

200
00:10:29.090 --> 00:10:33.238
But it doesn't matter, at first, kind of
what you choose, you want to be able to

201
00:10:33.238 --> 00:10:36.532
say craft the solution and
then kind of hang on to it for a moment.

202
00:10:36.532 --> 00:10:40.360
And try to do some secondary
analyses around it to see

203
00:10:40.360 --> 00:10:43.090
if your initial solution holds up.

204
00:10:43.090 --> 00:10:46.380
So the idea is that you wanna build, if
you're kinda making a case for something,

205
00:10:46.380 --> 00:10:48.880
you wanna build some prima facie evidence.

206
00:10:48.880 --> 00:10:52.570
And so that prima facie evidence
is really this initial solution,

207
00:10:52.570 --> 00:10:56.560
is the simplest solution that
you can think of at the moment.

208
00:10:56.560 --> 00:10:59.580
And then you try to pick away
at it to see if it falls apart.

209
00:10:59.580 --> 00:11:04.000
But one of the endpoints of exploratory
data analysis is to develop this prima

210
00:11:04.000 --> 00:11:06.450
facie case to develop this primary model.

211
00:11:08.270 --> 00:11:11.325
So once you've gone through this process,
you've looked at the data,

212
00:11:11.325 --> 00:11:14.900
you've checked to see that everything's
valid, you wanna be able to follow up.

213
00:11:14.900 --> 00:11:18.170
Okay, so this is the point where you ask
yourself those three questions that we

214
00:11:18.170 --> 00:11:19.490
talked about in the beginning.

215
00:11:19.490 --> 00:11:20.440
Do you have the right data?

216
00:11:20.440 --> 00:11:22.800
Do you need to get other data, right?

217
00:11:22.800 --> 00:11:24.050
So do you need to collect more?

218
00:11:24.050 --> 00:11:25.965
Do you need to ask for more?

219
00:11:25.965 --> 00:11:27.305
In order to answer.

220
00:11:27.305 --> 00:11:32.465
And do you have the right question, or
does it need to be refined a little bit?

221
00:11:32.465 --> 00:11:36.015
So once you're here,
you may need to slightly

222
00:11:36.015 --> 00:11:39.340
revise a few things with your data and
with your question.

223
00:11:39.340 --> 00:11:42.888
But once you've done that, if you wanna
move on, then you can start using

224
00:11:42.888 --> 00:11:46.725
exploratory data analysis techniques
to kinda refine your primary model, and

225
00:11:46.725 --> 00:11:48.863
then move on later into
a more formal model.