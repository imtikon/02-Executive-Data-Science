WEBVTT

1
00:00:02.712 --> 00:00:07.635
Hi, my name is Brian Caffo, and this
is the second lecture of the executive

2
00:00:07.635 --> 00:00:12.110
data science specialization course
on data analysis in real life.

3
00:00:13.230 --> 00:00:14.280
So in this lecture,

4
00:00:14.280 --> 00:00:18.680
I'd like to talk about machine learning
versus traditional statistics,

5
00:00:18.680 --> 00:00:24.600
just to orient you to the way I think
about the difference between the two.

6
00:00:24.600 --> 00:00:29.370
And why most of what I'm going to
talk about in the subsequent lectures

7
00:00:29.370 --> 00:00:31.880
really applies to more
traditional statistics.

8
00:00:31.880 --> 00:00:35.720
But it also somewhat applies to machine
learning, and in this lecture I'll tell

9
00:00:35.720 --> 00:00:38.490
you the difference, or
at least how I perceive the difference.

10
00:00:39.960 --> 00:00:40.640
In this lecture,

11
00:00:40.640 --> 00:00:44.390
we'd like to contrast machine learning
versus more traditional statistics.

12
00:00:44.390 --> 00:00:49.130
Because some of what we're gonna cover
in subsequent lectures is universally

13
00:00:49.130 --> 00:00:50.520
applicable to both.

14
00:00:50.520 --> 00:00:53.770
However, some of it is
really more oriented toward

15
00:00:53.770 --> 00:00:55.630
traditional statistical analysis.

16
00:00:55.630 --> 00:00:58.520
And in this lecture, I'm going to
tell you kind of what I perceive

17
00:00:58.520 --> 00:01:00.230
to be the difference between the two.

18
00:01:00.230 --> 00:01:03.450
So it's very kind of oriented
toward my impressions.

19
00:01:05.280 --> 00:01:09.820
So here's my sort of boiler plate

20
00:01:09.820 --> 00:01:12.970
bifurcation of these
two style of analysis.

21
00:01:12.970 --> 00:01:18.100
So to me, machine learning really
emphasizes things like predictions.

22
00:01:18.100 --> 00:01:22.550
And so, it tends to evaluate performance
via prediction performance, and

23
00:01:22.550 --> 00:01:23.950
we'll go through some examples later on.

24
00:01:24.960 --> 00:01:29.456
So there's a lot of concern in
machine learning for overfitting,

25
00:01:29.456 --> 00:01:34.687
that's fitting way too complex of a model,
but not model complexity per se.

26
00:01:34.687 --> 00:01:37.567
If you do good prediction and
you're not overfitting,

27
00:01:37.567 --> 00:01:41.890
then it's okay to have a rather
complex model in machine learning.

28
00:01:41.890 --> 00:01:45.130
So the emphasis is on performance and
automated learning.

29
00:01:46.430 --> 00:01:49.850
And generalizability is usually

30
00:01:49.850 --> 00:01:54.070
obtained through performance of
the algorithm on novel datasets.

31
00:01:54.070 --> 00:01:57.830
So machine learning tends to be
a very data oriented disappoint.

32
00:01:57.830 --> 00:02:01.760
So if you want to discuss that
your machine learning algorithm

33
00:02:01.760 --> 00:02:06.370
is generalizable, usually there's a sort
of show me attitude in machine learning.

34
00:02:06.370 --> 00:02:08.080
Get a new dataset and apply it to that.

35
00:02:09.210 --> 00:02:13.390
And there's usually no
superpopulation model specified.

36
00:02:13.390 --> 00:02:17.551
So there's no, my data is a sample
from a larger population,

37
00:02:17.551 --> 00:02:22.121
and I'm thinking of it this way
through statistical assumptions.

38
00:02:22.121 --> 00:02:27.341
And there is a lot of concern
over performance and robustness.

39
00:02:27.341 --> 00:02:32.250
So let's contrast this with
traditional statistical analysis.

40
00:02:32.250 --> 00:02:36.300
So traditional statistical analysis
focuses on so-called superpopulation

41
00:02:36.300 --> 00:02:36.980
inference.

42
00:02:36.980 --> 00:02:38.057
We have a dataset.

43
00:02:38.057 --> 00:02:42.237
We're gonna assume that that data set is
a sample from a larger population that we

44
00:02:42.237 --> 00:02:43.290
are interested in.

45
00:02:44.430 --> 00:02:47.410
And it tends to focus
on A-Priori Hypotheses.

46
00:02:47.410 --> 00:02:51.200
Your hypotheses are specified A-Priori.

47
00:02:51.200 --> 00:02:52.160
And in general,

48
00:02:52.160 --> 00:02:56.750
there's this principal of parsimony
in traditional statistical analysis.

49
00:02:56.750 --> 00:03:00.245
And that's basically saying,
all us being equal the simpler models

50
00:03:00.245 --> 00:03:03.140
gonna be preferred over
a more complex model.

51
00:03:03.140 --> 00:03:07.570
And I would go even further, that most
traditional statisticians would say

52
00:03:07.570 --> 00:03:11.120
even if you take a ding on
prediction performance,

53
00:03:11.120 --> 00:03:16.040
even if your model isn't performing that
well, you'd rather have a simpler model

54
00:03:16.040 --> 00:03:19.570
than a complex model unless
the difference in performance is extreme.

55
00:03:21.990 --> 00:03:24.354
In traditional statistical analysis,

56
00:03:24.354 --> 00:03:27.349
you emphasize parameter
interpretability a lot.

57
00:03:27.349 --> 00:03:29.958
In contrast to machine learning
where you may have lots and

58
00:03:29.958 --> 00:03:31.501
lots of parameters in your model,

59
00:03:31.501 --> 00:03:35.390
your algorithm that you don't really
care about those individual parameters.

60
00:03:35.390 --> 00:03:39.700
But in a regression analysis, for example,
you care about every one of the slopes.

61
00:03:41.360 --> 00:03:46.930
So the other super population inference,
so typically

62
00:03:46.930 --> 00:03:51.920
we have a statistical model that connects
our data to this super population.

63
00:03:51.920 --> 00:03:54.788
That's the crux of statistical modeling.

64
00:03:54.788 --> 00:03:58.700
So some sorta statistical model, or
even in non-parametric settings or

65
00:03:58.700 --> 00:04:01.950
robust settings,
we often have sampling assumptions.

66
00:04:01.950 --> 00:04:04.950
That connect our data to the population.

67
00:04:04.950 --> 00:04:08.080
And so, just like machine learning,
there's concern over robustness.

68
00:04:08.080 --> 00:04:11.720
But there's also this large concern over
the status statistical assumptions that

69
00:04:11.720 --> 00:04:14.290
connect our data to the population.

70
00:04:14.290 --> 00:04:16.515
So let's go through some examples.

71
00:04:16.515 --> 00:04:19.536
And I picked mostly prediction
examples that I'm gonna talk,

72
00:04:19.536 --> 00:04:23.469
if I were to have approached this problem
as a traditional statistical analysis,

73
00:04:23.469 --> 00:04:25.360
what I would have done.

74
00:04:25.360 --> 00:04:28.080
So one of the most famous prediction
problems, in recent years,

75
00:04:28.080 --> 00:04:29.440
was the Netflix Prize.

76
00:04:30.520 --> 00:04:34.410
And in the Netflix Prize, the teams
competed to produce the best recommender

77
00:04:34.410 --> 00:04:36.390
system for the company, Netflix.

78
00:04:36.390 --> 00:04:40.600
So they wanted to recommend, to users,
new movies that they might like.

79
00:04:40.600 --> 00:04:43.260
Through their star ratings system.

80
00:04:43.260 --> 00:04:46.370
The Netflix Prize was interesting,
because it was a $1 million prize.

81
00:04:46.370 --> 00:04:50.360
And some good friends of
the team here actually won.

82
00:04:50.360 --> 00:04:55.913
A close friend, Chris Valencia,
a great data scientist who works at AT&T.

83
00:04:55.913 --> 00:05:01.662
So the goal of this prize, and
his team won, the goal of this prize was

84
00:05:01.662 --> 00:05:08.220
to build a machine learning algorithm
that produced these recommendations.

85
00:05:09.470 --> 00:05:11.700
So that you wanted it to be automated.

86
00:05:11.700 --> 00:05:14.960
You wanted it to be something that
could be adaptive that maybe could

87
00:05:14.960 --> 00:05:17.740
relearn the algorithm as needed, and

88
00:05:17.740 --> 00:05:22.210
you would define success as anything
that produced reliable recommendations.

89
00:05:22.210 --> 00:05:27.280
And you can check that by when people

90
00:05:27.280 --> 00:05:31.260
watch a movie, and
actually then subsequently rate it.

91
00:05:31.260 --> 00:05:33.710
If they rate it high,
then it was a good recommendation,

92
00:05:33.710 --> 00:05:36.140
if they rate it low then it
was a poor recommendation.

93
00:05:36.140 --> 00:05:38.770
So that's the goal of
the machine learning analysis.

94
00:05:38.770 --> 00:05:42.260
But what if you were to
approach this same problem

95
00:05:42.260 --> 00:05:44.650
with a traditional statistical analysis?

96
00:05:44.650 --> 00:05:46.310
Well rather than building an algorithm,

97
00:05:46.310 --> 00:05:48.480
what you would wanna do is
build a parsimonious and

98
00:05:48.480 --> 00:05:54.080
interpretable model to better understand
why people choose the movies that they do.

99
00:05:54.080 --> 00:05:58.963
So you'd be much more interested in
where the sample of people that you

100
00:05:58.963 --> 00:06:00.370
are interested in,

101
00:06:00.370 --> 00:06:04.617
were they representative of
the totality of Netflix users.

102
00:06:04.617 --> 00:06:09.294
Or if you wanted to generalize,
not just the Netflix users in general, but

103
00:06:09.294 --> 00:06:14.491
to movie watchers in general, you'd wanna
know to what extent are my Netflix users

104
00:06:14.491 --> 00:06:19.790
in my sample representative of the larger
population of movie watchers in general.

105
00:06:20.880 --> 00:06:25.030
So in this case, you would be
building probably smaller models,

106
00:06:25.030 --> 00:06:30.400
you'd be trying to get very interpretable
results, interpretable parameters.

107
00:06:30.400 --> 00:06:34.110
And you would define
success as anything true

108
00:06:34.110 --> 00:06:36.030
that was learned about movies choices.

109
00:06:36.030 --> 00:06:41.030
So if you learned that certain
demographics like certain kinds of movies,

110
00:06:41.030 --> 00:06:43.820
or you learn that people who,

111
00:06:43.820 --> 00:06:48.300
psychological reasons why people like
certain movies, or anything that was true.

112
00:06:48.300 --> 00:06:52.950
And parsimonious learned about movie
choices would be the hopeful result,

113
00:06:52.950 --> 00:06:56.280
the hopeful success of such
a statistical analysis,

114
00:06:56.280 --> 00:06:59.450
even if you didn't gain
any better prediction.

115
00:06:59.450 --> 00:07:03.710
You can learn something true, but that
may not really help you with prediction.

116
00:07:05.680 --> 00:07:10.080
Another example that I was involved
in was the Heritage Health Prize.

117
00:07:10.080 --> 00:07:14.920
So this was actually a slightly bigger,
in terms of the monetary

118
00:07:14.920 --> 00:07:19.360
payout, prediction competition.

119
00:07:19.360 --> 00:07:23.300
In this case,
the goal was to take previous years',

120
00:07:23.300 --> 00:07:27.000
previous couple of years',
insurance claims.

121
00:07:27.000 --> 00:07:32.330
And try and predict how long
a person would spend in the hospital

122
00:07:32.330 --> 00:07:33.495
in subsequent years.

123
00:07:33.495 --> 00:07:39.710
So for example, just because we spent
a lot of time on this prediction,

124
00:07:39.710 --> 00:07:45.420
an example,
one that we found was if a woman was

125
00:07:45.420 --> 00:07:50.870
in the hospital, for
a hospital stay for a baby, then

126
00:07:50.870 --> 00:07:56.140
two years later they had a higher, they
were more likely to be in the hospital

127
00:07:56.140 --> 00:08:00.870
again just because a lot of people tend
to have babies about two years apart.

128
00:08:02.150 --> 00:08:07.146
So that was an example of a predictor so
for among women With having had

129
00:08:07.146 --> 00:08:12.489
a hospital stay for having a child two
years pervious, they had a slightly

130
00:08:12.489 --> 00:08:17.764
increased prediction of being in
the hospital two years subsequently.

131
00:08:17.764 --> 00:08:19.910
And then there were some
other obvious ones.

132
00:08:19.910 --> 00:08:23.160
For example, people who are in for
cardiac problems and things like that,

133
00:08:23.160 --> 00:08:26.209
tended to have an elevated risk of
being in the hospital the next year.

134
00:08:27.590 --> 00:08:30.640
So at any rate,
the machine learning algorithm for

135
00:08:30.640 --> 00:08:33.730
this problem,
which we spent a lot of time building,

136
00:08:33.730 --> 00:08:39.310
was basically to build an automated
system for predicting hospital stays.

137
00:08:39.310 --> 00:08:43.350
So you'd want, if you were a hospital
provider or something like this,

138
00:08:44.520 --> 00:08:47.959
you would want to know from the collection
of previous claims that you have

139
00:08:49.640 --> 00:08:54.670
what exactly, how long people would
spend in a hospital in subsequent years.

140
00:08:54.670 --> 00:08:57.730
And you could evaluate that,
again, like most things,

141
00:08:57.730 --> 00:09:03.030
you would want the system to be able to
relearn itself over time as things change.

142
00:09:03.030 --> 00:09:05.570
And you'd want it to be robust and, but

143
00:09:05.570 --> 00:09:08.460
success would be anything that
produces reliable predictions.

144
00:09:08.460 --> 00:09:11.030
And anything that produces
more reliable predictions

145
00:09:11.030 --> 00:09:15.060
is better than something that
produces less reliable predictions.

146
00:09:15.060 --> 00:09:18.440
And you could come up with a pretty
simple formula to define what you meant

147
00:09:18.440 --> 00:09:19.880
by good predictions.

148
00:09:21.270 --> 00:09:23.264
By the way, in this case,
I think we got 12.

149
00:09:23.264 --> 00:09:27.927
We were listed as 14th, but
2 other teams got disqualified, so

150
00:09:27.927 --> 00:09:32.950
we came up with 12th, and
it was a 3-year prediction competition.

151
00:09:32.950 --> 00:09:34.640
Or two-year prediction competition.

152
00:09:34.640 --> 00:09:36.760
And by the end things got pretty grim.

153
00:09:36.760 --> 00:09:39.460
We have to come up with
a prediction every single day.

154
00:09:39.460 --> 00:09:43.320
And boy, were we tired of building
prediction algorithms by the end.

155
00:09:43.320 --> 00:09:45.840
So I would just give you as a caveat,

156
00:09:45.840 --> 00:09:49.090
if you ever intend to enter into
one of these competitions, think

157
00:09:49.090 --> 00:09:52.350
a year later down the road if you wanna
be building predictions every single day.

158
00:09:54.940 --> 00:09:59.790
So let's now contrast what
I would have done if,

159
00:09:59.790 --> 00:10:05.060
instead of engaging in this prediction
competition, if I had been interested in

160
00:10:05.060 --> 00:10:09.340
the science of insurance claims and
hospital stays.

161
00:10:09.340 --> 00:10:13.630
Well, then I would want to perform
a more traditional statistical analysis.

162
00:10:13.630 --> 00:10:16.540
I'd want to build a parsimonious
interpreter model.

163
00:10:16.540 --> 00:10:20.870
And I would want to figure out things
like what I mentioned earlier about

164
00:10:20.870 --> 00:10:22.070
the issue with the pregnant women.

165
00:10:22.070 --> 00:10:25.070
Now, that probably wouldn't be
terribly of interest to scientists or

166
00:10:25.070 --> 00:10:28.360
medical practitioners any of them,
because it's just a kind of quirky little,

167
00:10:28.360 --> 00:10:30.190
it's just a demographic fact really.

168
00:10:32.110 --> 00:10:35.700
But you might wanna learn if there's
certain combinations of the claims that

169
00:10:35.700 --> 00:10:39.510
might lead to a greater propensity for
hospital stays,

170
00:10:39.510 --> 00:10:42.960
which might then lead to the ability
to treat people earlier.

171
00:10:44.090 --> 00:10:45.720
So success, in this case,

172
00:10:45.720 --> 00:10:50.750
would be anything that was learned about
hospital stays from insurance claims data.

173
00:10:52.950 --> 00:10:57.370
Another very famous prediction
example was the Google flu trends.

174
00:10:57.370 --> 00:11:00.770
This came out several years ago, and

175
00:11:00.770 --> 00:11:04.000
it was a very,
it generated a lot of excitement.

176
00:11:04.000 --> 00:11:08.980
And here, the very clever
people at Google came up with

177
00:11:08.980 --> 00:11:13.670
the idea that well they could maybe detect
flu outbreaks before the Centers for

178
00:11:13.670 --> 00:11:17.420
Disease Control by looking
at search terms and

179
00:11:17.420 --> 00:11:20.420
geographic information associated
with the search terms.

180
00:11:20.420 --> 00:11:24.950
So if lots of people were searching for
Tamiflu, or searching for

181
00:11:24.950 --> 00:11:26.810
headaches and fevers, etc.

182
00:11:26.810 --> 00:11:32.730
That might lead to a greater propensity,
or greater risk that a flu

183
00:11:32.730 --> 00:11:36.780
outbreak in that particular area where
most of the searches were coming from.

184
00:11:36.780 --> 00:11:39.750
So in this case, their goal was
to build an automated system for

185
00:11:39.750 --> 00:11:41.130
predicting flu outbreaks.

186
00:11:41.130 --> 00:11:46.020
And their success was anything that
produces reliable predictions as judged by

187
00:11:46.020 --> 00:11:51.090
the more thorough information that came
out from the CDC, but much slower.

188
00:11:51.090 --> 00:11:57.320
So their goal was to beat the CDC in
terms of time, but then they had the high

189
00:11:57.320 --> 00:12:00.840
quality data coming in a little bit later
to actually validate their algorithm.

190
00:12:02.120 --> 00:12:06.660
So contrast this with what flu
researchers, like I'm in the school public

191
00:12:06.660 --> 00:12:10.490
health at Johns Hopkins,
that flu researchers here do all the time.

192
00:12:10.490 --> 00:12:13.300
They want to better
understand flu outbreaks.

193
00:12:13.300 --> 00:12:17.720
So they want to build models that
helps us understand specifically why

194
00:12:17.720 --> 00:12:21.350
flu outbreaks occur in certain areas.

195
00:12:21.350 --> 00:12:24.300
So for them,
search terms probably wouldn't be enough.

196
00:12:24.300 --> 00:12:30.320
They need more of the kind of information
that the CDC, for example, was collecting,

197
00:12:30.320 --> 00:12:35.857
which Includes actual prescription counts
for Tamiflu and that sort of thing.

198
00:12:35.857 --> 00:12:40.830
So again, so all of these examples really
emphasize, in my mind, kind of this big

199
00:12:40.830 --> 00:12:45.806
dividing line between what is typically
going on in a machine learning experiment

200
00:12:45.806 --> 00:12:50.589
versus what's typically going on in
a traditional statistical experiment.

201
00:12:51.900 --> 00:12:54.930
So I hope what I've emphasized
in this lecture is that

202
00:12:54.930 --> 00:12:58.500
both approaches are extremely valuable,
and they have their place.

203
00:12:58.500 --> 00:13:04.460
However, typically, the amount of model
complexity and assumptions, etc., differs

204
00:13:04.460 --> 00:13:09.690
quite a bit between the two approaches,
because their goals are very different.

205
00:13:09.690 --> 00:13:13.540
And I would just end this part of the
discussion with a little caveat that says,

206
00:13:13.540 --> 00:13:17.860
well there's the machine
learning community I've noticed,

207
00:13:17.860 --> 00:13:22.310
has started to build super population
models to evaluate their algorithms, and

208
00:13:22.310 --> 00:13:25.340
so they're kind of connecting
it to traditional statistics.

209
00:13:25.340 --> 00:13:29.681
In addition, there's been a lot of work
on making machine algorithm output in

210
00:13:29.681 --> 00:13:33.170
addition to producing these
ultra high quality predictions,

211
00:13:33.170 --> 00:13:35.360
making them much more interpretable.

212
00:13:36.870 --> 00:13:40.850
I've also seen a lot of people taking
traditional statistical approaches and

213
00:13:40.850 --> 00:13:45.060
building them up slightly in
terms of complexity to try and

214
00:13:45.060 --> 00:13:46.635
produce better predictions.

215
00:13:46.635 --> 00:13:50.765
So it's interesting that in a lot of ways
the two areas are meeting in the middle,

216
00:13:50.765 --> 00:13:54.169
and these distinctions that I've
outlined a lot in this lecture,

217
00:13:54.169 --> 00:13:57.975
that I am outlining a lot in this lecture,
are getting grayed quite a bit.