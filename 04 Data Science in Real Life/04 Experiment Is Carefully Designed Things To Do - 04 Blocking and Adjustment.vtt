WEBVTT

1
00:00:00.120 --> 00:00:04.460
Hi, I'm Brian Caffo and this is
the lecture on Blocking and Adjustment.

2
00:00:10.800 --> 00:00:15.860
So let's start talking about this
problem by putting it into a context.

3
00:00:17.140 --> 00:00:21.509
Imagine if you're looking at improving
mobility among the elderly and

4
00:00:21.509 --> 00:00:24.927
you want to do this using fitness tracker,
so I think for

5
00:00:24.927 --> 00:00:28.232
me the most famous fitness
tracker I think is Fitbit.

6
00:00:28.232 --> 00:00:32.504
And you want the fitness tracker to serve
as motivation for greater mobility.

7
00:00:32.504 --> 00:00:35.819
And you're gonna do a clinical
trial where you randomize

8
00:00:35.819 --> 00:00:41.060
half of your subjects to receive a Fitbit,
and the control subjects get nothing.

9
00:00:41.060 --> 00:00:44.870
But most clinical trials they get
something like the Fitbit at the end of

10
00:00:44.870 --> 00:00:48.070
the trial to reward them for
being in the study,

11
00:00:48.070 --> 00:00:49.160
in case you were worried about that.

12
00:00:50.460 --> 00:00:55.930
So you're worried that age would
confound the relationship and

13
00:00:55.930 --> 00:01:00.790
ideally, and likely in fact,
the age groups would be

14
00:01:00.790 --> 00:01:06.220
distributed In roughly equal proportions
among the treated and the controls.

15
00:01:06.220 --> 00:01:09.829
However, if you have a smaller study,
something like this might happen.

16
00:01:09.829 --> 00:01:14.380
You might get, at the younger age group,
one person who is a control.

17
00:01:14.380 --> 00:01:19.035
At the middle age group,
three people who are control, and

18
00:01:19.035 --> 00:01:23.874
the high age group in this case,
five people who are control,

19
00:01:23.874 --> 00:01:27.620
and each of those age
groups having six people.

20
00:01:29.440 --> 00:01:34.419
And, then, in this case, age will be
aliased with control status, right, for

21
00:01:34.419 --> 00:01:39.048
the younger ages, fewer controls,
for the higher ages, more controls.

22
00:01:39.048 --> 00:01:43.517
And so if you were to look at
the relationship between the fitness

23
00:01:43.517 --> 00:01:45.851
tracker and measured mobility.

24
00:01:45.851 --> 00:01:50.790
You would then be worried that
it's actually associated with age.

25
00:01:50.790 --> 00:01:52.750
And this would be
an unlucky arrangement and

26
00:01:52.750 --> 00:01:58.040
if you had enough subjects, probably
things would wash out just by probability.

27
00:01:58.040 --> 00:02:02.850
But because you know age is such
an important factor, a priori, you might

28
00:02:02.850 --> 00:02:07.840
wanna force it to be equal within your
age categories you might want to take and

29
00:02:07.840 --> 00:02:11.410
get six people who are age 65 to 70 and

30
00:02:11.410 --> 00:02:15.910
then randomize them on those six people
three to receive the treatment and

31
00:02:15.910 --> 00:02:19.340
three to receive the control and
this is called blocking.

32
00:02:19.340 --> 00:02:24.266
And it's basically, the principle that
if you know that an important source

33
00:02:24.266 --> 00:02:29.041
of explanatory variation exists as
a variable, why don't you control for

34
00:02:29.041 --> 00:02:32.784
it at the onset,
at the stage of the experimental design?

35
00:02:36.429 --> 00:02:40.663
Let's talk about a related problem
when you don't have control over

36
00:02:40.663 --> 00:02:44.532
the experiment, or
when you've conducted the experiment and

37
00:02:44.532 --> 00:02:47.680
realize that there was
some sort of aliasing.

38
00:02:47.680 --> 00:02:50.580
So, for example, you might have
conducted this experiment, and

39
00:02:50.580 --> 00:02:52.440
actually there was an aliasing.

40
00:02:52.440 --> 00:02:53.310
What could you have done?

41
00:02:54.670 --> 00:02:59.647
So you are studying the elderly still and
you are comparing the use of

42
00:02:59.647 --> 00:03:04.799
trackers with mobility, but
you are just observing the collection of

43
00:03:04.799 --> 00:03:10.402
people who self-select into using
fitness trackers versus the controls.

44
00:03:10.402 --> 00:03:15.113
And so you're worried about because it's
an observation study, you're worried about

45
00:03:15.113 --> 00:03:19.070
lots of factors that might confound
the relationship between mobility and

46
00:03:19.070 --> 00:03:20.468
use of a fitness tracker.

47
00:03:20.468 --> 00:03:23.364
However, you're very concerned
about age in specific, so

48
00:03:23.364 --> 00:03:26.599
let's just talk about that one variable,
while we would note, for

49
00:03:26.599 --> 00:03:30.320
a full observational study,
we'd be concerned about lots of things.

50
00:03:30.320 --> 00:03:32.580
But, you're worried about
the age distribution.

51
00:03:32.580 --> 00:03:37.140
The younger subjects are gonna be more
likely to pick up a fitness tracker just

52
00:03:37.140 --> 00:03:41.110
because of level of comfort with
technology and other factors like that.

53
00:03:41.110 --> 00:03:43.980
And so you're worried any
results you see aren't gonna be

54
00:03:43.980 --> 00:03:47.520
really associated with just
differential age distributions.

55
00:03:49.310 --> 00:03:54.520
So how can, what's the most common way
to look at this, to solve this problem.

56
00:03:54.520 --> 00:03:56.040
And this is the idea of adjustment.

57
00:03:57.290 --> 00:04:00.330
And so adjustment is the idea
of looking at the relationship

58
00:04:00.330 --> 00:04:02.930
within levels of
the confounder held fixed.

59
00:04:02.930 --> 00:04:07.480
So we would look at, say for
example, the middle age group,

60
00:04:07.480 --> 00:04:12.400
we would compare the mobility
with the age group held fixed, so

61
00:04:12.400 --> 00:04:13.890
we're still comparing like with like.

62
00:04:13.890 --> 00:04:17.790
Now we may not have equal numbers
of subjects in that age group, but

63
00:04:17.790 --> 00:04:22.800
we will have fixed the age group so age
isn't varying in that comparison, okay?

64
00:04:22.800 --> 00:04:27.070
So there's lots of different
ways to do adjustment.

65
00:04:27.070 --> 00:04:28.560
But perhaps the most common and

66
00:04:28.560 --> 00:04:33.490
straightforward and easiest one to do
is so called regression adjustment.

67
00:04:33.490 --> 00:04:36.780
And this is when if we
want to look at Fitbit or

68
00:04:36.780 --> 00:04:40.790
not as a variable in a regression
analysis, what do we do?

69
00:04:40.790 --> 00:04:44.880
We add age as another variable
in that regressional analysis.

70
00:04:44.880 --> 00:04:48.090
And that performs a sort of adjustment,
and

71
00:04:48.090 --> 00:04:50.880
I'm gonna go through some
examples to show you, but

72
00:04:50.880 --> 00:04:56.090
also go through some examples to show
you that adjustment is why you can get

73
00:04:56.090 --> 00:05:00.220
strange things happening when you add in
a new variable into a regression model.

74
00:05:01.640 --> 00:05:06.450
So here's a pretty simple example,
so here, again, the gray people

75
00:05:06.450 --> 00:05:10.950
are people who self-selected into using
a Fitbit, and the red people are the ones

76
00:05:10.950 --> 00:05:14.080
who are the control,
are the ones who don't use a Fitbit.

77
00:05:15.120 --> 00:05:20.369
And the Y-axis is a measure of mobility,
and the X-axis is a measure of age.

78
00:05:21.570 --> 00:05:25.550
In this set, in this example you can look,
the mean for

79
00:05:25.550 --> 00:05:30.270
the gray faces is higher than
the mean mobility for the red faces.

80
00:05:30.270 --> 00:05:33.995
So the unadjusted effect is large.

81
00:05:33.995 --> 00:05:38.035
As we adjust it we see that there's
this line of mobility with age.

82
00:05:38.035 --> 00:05:41.988
However, and those lines are parallel
we're gonna stick with just the setting

83
00:05:41.988 --> 00:05:44.300
where the lines are parallel
in our examples.

84
00:05:46.520 --> 00:05:49.470
And the lines are parallel, but
the difference between the parallel

85
00:05:49.470 --> 00:05:51.950
lines is about the same as
the difference in the means.

86
00:05:51.950 --> 00:05:55.240
So adjustment didn't really do much in
this case, other than give us peace of

87
00:05:55.240 --> 00:06:01.010
mind that our fact wasn't entirely due
to just differential age distribution.

88
00:06:01.010 --> 00:06:04.830
But notice one reason why
the adjustment didn't change much.

89
00:06:04.830 --> 00:06:09.040
First of all, the data really suggests
that the lines are parallel, but

90
00:06:09.040 --> 00:06:10.730
secondly there's a large overlap.

91
00:06:10.730 --> 00:06:18.570
At every age distribution you see people
with both control and having Fitbits.

92
00:06:18.570 --> 00:06:21.810
Okay, so at every H distribution
there is a lot of overlap.

93
00:06:21.810 --> 00:06:25.960
So there's a lot of data to
directly make this comparison.

94
00:06:25.960 --> 00:06:27.980
Consider this example.

95
00:06:27.980 --> 00:06:32.790
In this example the marginal mean,
the mean for the red group,

96
00:06:32.790 --> 00:06:39.290
disregarding age, is higher than the mean
for the gray group, disregarding age.

97
00:06:39.290 --> 00:06:43.630
However, when we fit the regression
model with age in it,

98
00:06:43.630 --> 00:06:48.240
we fit two parallel lines, and notice
that the parallel lines would suggest

99
00:06:48.240 --> 00:06:51.100
that the gray group is
the higher than the red group.

100
00:06:51.100 --> 00:06:58.640
Okay, that the Fitbit mobility is
higher than the Control mobility.

101
00:06:58.640 --> 00:07:01.980
And what this is an example of this
is an example where the effect

102
00:07:01.980 --> 00:07:03.610
would actually reverse itself.

103
00:07:03.610 --> 00:07:08.950
It would've gone from a significant effect
but in one direction to a significant

104
00:07:08.950 --> 00:07:14.310
effect in the other direction after the
inclusion of age in our regression model.

105
00:07:14.310 --> 00:07:18.610
So this serves as an example to show why
it is when someone is reporting to you to

106
00:07:18.610 --> 00:07:23.830
a data analysis, and you say, okay,
I'm concerned that age might be

107
00:07:23.830 --> 00:07:27.290
causing this problem, and
they run the analysis real quick, and

108
00:07:27.290 --> 00:07:31.640
the effect actually reverses itself,
it's because of a phenomena like this.

109
00:07:31.640 --> 00:07:36.700
I would also notice, look at this
particular example, another hallmark of it

110
00:07:36.700 --> 00:07:43.030
is there's almost no overlap, there's
almost no ages where there's direct data

111
00:07:43.030 --> 00:07:49.730
to compare the fitness trackers with the
use of a fitness tracker with mobility.

112
00:07:49.730 --> 00:07:53.800
Only in this sort of middle age range
is there just a couple of people

113
00:07:53.800 --> 00:07:54.790
who are overlapped.

114
00:07:54.790 --> 00:07:58.370
Otherwise, it's basically the old
people don't use fitness trackers, and

115
00:07:58.370 --> 00:08:00.740
the young people all do
use fitness trackers.

116
00:08:00.740 --> 00:08:03.180
So this data, our results,

117
00:08:03.180 --> 00:08:06.860
our adjusted results will be
heavily dependent on our model.

118
00:08:09.880 --> 00:08:14.840
Here's an example where the marginal mean,
the mean without considering age, for

119
00:08:14.840 --> 00:08:17.930
the control group, the red faces,

120
00:08:17.930 --> 00:08:24.020
is higher than that of the gray group,
again they're lower.

121
00:08:24.020 --> 00:08:28.420
However, when we adjust for age,
notice the lines appear to be the same,

122
00:08:28.420 --> 00:08:30.050
there appears to be no difference.

123
00:08:30.050 --> 00:08:34.010
So, this would be an instance where you
would have a strongly significant effect

124
00:08:34.010 --> 00:08:37.290
if you didn't factor in age,
but once you accounted for

125
00:08:37.290 --> 00:08:40.210
age in your regression model,
it went away.

126
00:08:40.210 --> 00:08:42.120
Okay, everything just
lied on the same line.

127
00:08:42.120 --> 00:08:43.610
So if you disregarded age.

128
00:08:43.610 --> 00:08:45.130
So this is just an example of,

129
00:08:45.130 --> 00:08:50.690
again, how your effect can really change
after the inclusion of another variable.

130
00:08:50.690 --> 00:08:55.040
Oh, and notice again in this one there
isn't a lot of direct overlap; a lot of

131
00:08:55.040 --> 00:08:58.990
instances of direct comparability
between the groups.

132
00:08:58.990 --> 00:09:03.210
If there is a lot of direct comparability
then the adjustment doesn't tend to

133
00:09:03.210 --> 00:09:06.800
change much, and

134
00:09:06.800 --> 00:09:11.490
in this case, here's an instance
where the mean disregarding age of

135
00:09:11.490 --> 00:09:16.380
both groups is about the same, but
when we fit the model adjusted for

136
00:09:16.380 --> 00:09:20.370
age, the two parallel line's we're
fitting will be quite different

137
00:09:20.370 --> 00:09:24.240
in terms of their intercept or the shift
between the lines would be quite high.

138
00:09:24.240 --> 00:09:28.700
And so, this would be an instance of when
it went from a non-significant effect

139
00:09:28.700 --> 00:09:32.740
if we disregarded h, to a highly
significant effect when we thought,

140
00:09:32.740 --> 00:09:33.470
when we included h.

141
00:09:37.420 --> 00:09:38.210
The final example,

142
00:09:38.210 --> 00:09:43.450
I want to make this point one more time,
and what I wanted to say is in this case,

143
00:09:43.450 --> 00:09:48.410
once you fit the model there would be a
big effect between the two parallel lines.

144
00:09:48.410 --> 00:09:50.840
They look very different in this case,
however,

145
00:09:50.840 --> 00:09:53.770
one thing I wanna mention,
in this case there's no overlap.

146
00:09:53.770 --> 00:10:00.093
There's no ages where we observe
both control and treated group or

147
00:10:00.093 --> 00:10:05.531
control and self-selected Fitbit users.

148
00:10:05.531 --> 00:10:11.950
So this the result would be all model and
no data, right?

149
00:10:11.950 --> 00:10:15.920
The comparison we would be making would
be extrapolating the line from the gray

150
00:10:15.920 --> 00:10:20.830
group on upward and extrapolating
the line from the red group downward.

151
00:10:20.830 --> 00:10:25.880
So there's no data overlap
to inform this decision.

152
00:10:25.880 --> 00:10:28.760
This is something to think about

153
00:10:28.760 --> 00:10:32.710
that regression does not handle by itself,
right.

154
00:10:32.710 --> 00:10:37.910
It does not tell you that the comparison
you're making has a lot of data.

155
00:10:37.910 --> 00:10:41.360
So I think it's often good to ask
the people that you're managing

156
00:10:41.360 --> 00:10:42.690
to do some basic plots.

157
00:10:42.690 --> 00:10:48.210
In this case you would want to look at
the correlation of age with Fitbit use and

158
00:10:48.210 --> 00:10:51.810
if it's highly correlated
than that's a problem.

159
00:10:51.810 --> 00:10:54.140
Right, in this case,
you could perfectly pick,

160
00:10:54.140 --> 00:10:57.450
predict their Fitbit usage by their age.

161
00:10:57.450 --> 00:11:01.090
If they were above this middle age rung,
they all used Fitbit and

162
00:11:01.090 --> 00:11:03.190
if they were below that,
they didn't use Fitbit.

163
00:11:03.190 --> 00:11:05.810
And whenever you can,
whenever that can happen.

164
00:11:05.810 --> 00:11:09.250
Whenever your confounder predicts
your regression very well

165
00:11:09.250 --> 00:11:11.920
that you're interested in,
then that's a problem.

166
00:11:14.040 --> 00:11:17.130
Okay, so thanks for
listening to this lecture and

167
00:11:17.130 --> 00:11:21.550
I hope you learned a little bit about two
common strategies, one blocking, something

168
00:11:21.550 --> 00:11:24.960
that we do as part of our experimental
design and another: adjustment,

169
00:11:24.960 --> 00:11:29.230
something that we do after we've
collected data to try and account for

170
00:11:29.230 --> 00:11:33.370
confounding variables that may contaminate
relationships that we're interested in.

171
00:11:34.380 --> 00:11:36.220
Thanks again and
I'll see you in the next lecture.